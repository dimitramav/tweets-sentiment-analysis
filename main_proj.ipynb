{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sentiment': 'positive', 'text': 'Gas by my house hit 339 Im going to Chapel Hill on Sat  ðŸ˜‚'}, {'sentiment': 'negative', 'text': 'Theo Walcott is still shit watch Rafa and Johnny deal with him on Saturday'}, {'sentiment': 'negative', 'text': 'its not that Im a GSP fan i just hate Nick Diaz cant wait for february'}, {'sentiment': 'negative', 'text': 'Iranian general says Israels Iron Dome cant deal with their missiles keep talking like that and we may end up finding out'}, {'sentiment': 'neutral', 'text': 'Tehran Mon Amour Obama Tried to Establish Ties with the Mullahs  via No Barack Obama  Vote Mitt Romney'}, {'sentiment': 'neutral', 'text': 'I sat through this whole movie just for Harry and Ron at christmas ohlawd 911'}, {'sentiment': 'neutral', 'text': 'Mashed out to Niggas In Paris in the club while in Paris as cliche as it may sound WeOutHere'}, {'sentiment': 'neutral', 'text': 'Larry Bird is ranked 4th alltime not including Lebron or Kobe just sayin'}]\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "##### STRIP TWEET #####################################\n",
    "#######################################################\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "f = open(\"small.tsv\")\n",
    "line = f.readline()\n",
    "\n",
    "tweets = []\n",
    "translate_table = dict((ord(char), None) for char in string.punctuation)   \n",
    "cnt = 1\n",
    "while line:\n",
    "    pretext = ' '.join(line.split()[3:])\n",
    "    pretext = ' '.join(word for word in pretext.split(' ') if not word.startswith('@')) #remove @user\n",
    "    pretext = re.sub(r\"http\\S+\", \"\", pretext) #remove link\n",
    "    pretext = pretext.translate(translate_table) #remove symbols \n",
    "    #remove numbers??\n",
    "    \n",
    "    tweet = {\n",
    "        \"sentiment\": ' '.join(line.split()[2:3]),\n",
    "        \"text\": pretext\n",
    "    }\n",
    "    tweets.append(tweet)\n",
    "    line = f.readline()\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sentiment': 'positive', 'text': ['Gas', 'by', 'my', 'house', 'hit', '339', 'Im', 'going', 'to', 'Chapel', 'Hill', 'on', 'Sat', 'ðŸ˜‚']}, {'sentiment': 'negative', 'text': ['Theo', 'Walcott', 'is', 'still', 'shit', 'watch', 'Rafa', 'and', 'Johnny', 'deal', 'with', 'him', 'on', 'Saturday']}, {'sentiment': 'negative', 'text': ['its', 'not', 'that', 'Im', 'a', 'GSP', 'fan', 'i', 'just', 'hate', 'Nick', 'Diaz', 'cant', 'wait', 'for', 'february']}, {'sentiment': 'negative', 'text': ['Iranian', 'general', 'says', 'Israels', 'Iron', 'Dome', 'cant', 'deal', 'with', 'their', 'missiles', 'keep', 'talking', 'like', 'that', 'and', 'we', 'may', 'end', 'up', 'finding', 'out']}, {'sentiment': 'neutral', 'text': ['Tehran', 'Mon', 'Amour', 'Obama', 'Tried', 'to', 'Establish', 'Ties', 'with', 'the', 'Mullahs', 'via', 'No', 'Barack', 'Obama', 'Vote', 'Mitt', 'Romney']}, {'sentiment': 'neutral', 'text': ['I', 'sat', 'through', 'this', 'whole', 'movie', 'just', 'for', 'Harry', 'and', 'Ron', 'at', 'christmas', 'ohlawd', '911']}, {'sentiment': 'neutral', 'text': ['Mashed', 'out', 'to', 'Niggas', 'In', 'Paris', 'in', 'the', 'club', 'while', 'in', 'Paris', 'as', 'cliche', 'as', 'it', 'may', 'sound', 'WeOutHere']}, {'sentiment': 'neutral', 'text': ['Larry', 'Bird', 'is', 'ranked', '4th', 'alltime', 'not', 'including', 'Lebron', 'or', 'Kobe', 'just', 'sayin']}]\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "##### TOKENIZATION ####################################\n",
    "#######################################################\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "for tweet in tweets:\n",
    "    tweet[\"text\"] = word_tokenize(tweet[\"text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
